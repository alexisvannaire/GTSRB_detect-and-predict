{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b5e7d1e",
   "metadata": {},
   "source": [
    "# Traffic signs detection and classification with Detecto and Tensorflow \n",
    "\n",
    "### Part 2 - *Object Detection*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ee5e9",
   "metadata": {},
   "source": [
    "All the functions and visualizations I used here can be found on my GitHub page: [https://github.com/alexisvannaire/GTSRB_detect-and-predict](https://github.com/alexisvannaire/GTSRB_detect-and-predict)\n",
    "\n",
    "See the first part (1_detect-and-predict) if you need details on the packages I used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c453c9",
   "metadata": {},
   "source": [
    "**For this notebook:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad30692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "\n",
    "import process_data # process_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9bfb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False for default visualizations and computations\n",
    "update_xml_filepaths = False # True if you want to update the paths in the xml files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b68318d",
   "metadata": {},
   "source": [
    "# III. Object Detection Model\n",
    "\n",
    "## 1. Models and preprocessing\n",
    "\n",
    "The best models for this task are **R-CNN** (Region Based CNN) and its derivatives.\n",
    "\n",
    "The R-CNNs aim to extract ROIs (Regions of Interest) from an image, where each one is a rectangle corresponding to the boundary of a potential object. Then, each ROI is passed through an usually pre-trained CNN in order to extract features. The feature vector is fed into a set of SVM (Support Vector Machine) classifiers, one for each object class, and they determine whether a specific object is present or not.\n",
    "\n",
    "Its derivatives are Fast R-CNN, Faster R-CNN,YOLO, SSD, RetinaNet, EfficientDet and MobileNets with SSD. \n",
    "And as you can guess from their names, these models try to improve the speed of object detection but also the accuracy compared to the standard R-CNN.\n",
    "\n",
    "The Detecto package provide a pre-trained *Faster R-CNN ResNet-50 FPN* from PyTorch's model zoo (you can find here: https://pytorch.org/serve/model_zoo.html). \n",
    "It allows us to easily build our first object detection model on a custom dataset and see how it works. \n",
    "\n",
    "The more images you have the better the model will be.\n",
    "A common suggestion is to label at least one hundred images per class.\n",
    "With theses 92 images randomly cropped 3 times each, we get a 276 images dataset (with likely more than one hundred traffic signs).\n",
    "That's okay for an introduction but for a more professional application you would use more labeled images, like around 400-500 images.\n",
    "But keep in mind that labeling images takes time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4548be",
   "metadata": {},
   "source": [
    "Here's how to proceed:\n",
    "\n",
    "1. create your own dataset (manually, with web scraping, from a video, or with an existing dataset)\n",
    "2. label the images\n",
    "3. train your model\n",
    "\n",
    "Of course you can tune some hyperparameters if you want to train several models.\n",
    "Also, you can get deeper by training models directly with tensorflow or pytorch libraries.\n",
    "\n",
    "This dataset comes from a video I recorded and split.\n",
    "Let's see how to label each image.\n",
    "\n",
    "We're going to use `labelImg` (https://github.com/HumanSignal/labelImg).\n",
    "\n",
    "Install the package, for example with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3065aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install labelImg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa76ac3b",
   "metadata": {},
   "source": [
    "Then, in your conda prompt run it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f166d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labelImg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94f092c",
   "metadata": {},
   "source": [
    "A windows will open and you'll have to choose your dataset directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"imgs/labelImg_open_dir.png\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a197505d",
   "metadata": {},
   "source": [
    "You'll have your images appearing and just click on `Create RectBox` to label them (or with a shortcut, mine was `W`).\n",
    "\n",
    "Label the object you want your model to detect by creating a rectangle around it and then associate the class name you want (note all your classes somewhere, you'll need to specify them before training the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc0f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"imgs/labelImg_label_imgs.png\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020110de",
   "metadata": {},
   "source": [
    "When you've finished to label an image, juste save it and it'll create a `.xml` file with the same name. Of course if an image doesn't contain any object you want to be detected, just pass to the next one (it just won't create a file)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a039c6f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Note:** If you want to use the dataset I created:\n",
    "    \n",
    "I wrote a python function that modifies the xml files in order to make it works. \n",
    "\n",
    "When you create a xml with labelImg and save it, the path will be written in each file and then depends on your computer. If you open any xml file you'll see it at the begining:\n",
    "\n",
    "`<path>project_path\\data\\google_maps_test\\labeled_imgs\\0-0.xml</path>`\n",
    "\n",
    "So if you want to use it, you can either change the \"project_path\" part into the absolute path where you placed it, e.g.: \n",
    "\n",
    "`<path>C:\\Users\\your_user_name\\Documents\\project_path\\data\\google_maps_test\\labeled_imgs\\0-0.xml</path>`\n",
    "\n",
    "Or, run the `update_xml_paths` function I created in the `process_data.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if update_xml_filepaths:\n",
    "    process_data.update_xml_paths()\n",
    "    print(\"xml paths updated.\")\n",
    "else:\n",
    "    print(\"xml paths not updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310fd5b",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f13ac18",
   "metadata": {},
   "source": [
    "I didn't tune the 3 models I trained. I just focused on right labeling and it took times! But feel free to try some other epcohs number, learning rates, custom transformations and even try with tensorflow or pytorch models.\n",
    "\n",
    "For the first model, I labeled two classes: `traffic_signs` and `vehicles` and train the model for 10 epochs.\n",
    "\n",
    "For the second one, I just added one class: `google_maps` because of some google maps icons you can find at some places. And deleted some labels on traffic signs that might be to small and that I didn't want to be predicted by the model (thinking it would bring confusion with some other small objects). I trained it for 10 epochs too.\n",
    "\n",
    "And the third was just like the second one but with 20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2238ed",
   "metadata": {},
   "source": [
    "Here's the few lines you have to write in order to train your model:\n",
    "\n",
    "* Load your dataset just by giving the folderpath:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2195d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = core.Dataset('data/google_maps_test/labeled_imgs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce6104a",
   "metadata": {},
   "source": [
    "* Initialize your model by giving the class names you gave during the labeling step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = core.Model(['traffic_sign', 'vehicle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb8b9d1",
   "metadata": {},
   "source": [
    "* Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66701604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac57d1c8",
   "metadata": {},
   "source": [
    "Despite the warning you can have if you don't have a GPU installed: \n",
    "\n",
    "`It looks like you're training your model on a CPU. Consider switching to a GPU; otherwise, this method can take hours upon hours or even days to finish.`\n",
    "\n",
    "you can try anyway because it could be not that long. For example for my two first models trained for 10 epochs each, it lasted around 3h 45 min.\n",
    "\n",
    "<br> \n",
    "\n",
    "Don't forget to save your model in order to be able to use it later and do predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badce3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('models/object_detection/model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de242c84",
   "metadata": {},
   "source": [
    "After, you could load it this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1584c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = core.Model.load('models/object_detection/model.pth', ['traffic_sign', 'vehicle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9409e18",
   "metadata": {},
   "source": [
    "## 3. Predictions\n",
    "\n",
    "We have one or several trained models and now we want to see how the predictions are.\n",
    "\n",
    "First, the model predictions from an image look like this: \n",
    "\n",
    "* a list of classes\n",
    "* a list of associated boxes coordinates (xmin, ymin, xmax, and ymax)\n",
    "* a list of associated probabilities\n",
    "\n",
    "Here's how you can get the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce0fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels, boxes, scores = model.predict(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4234d726",
   "metadata": {},
   "source": [
    "Depending of what you're interested in, you can filter the predictions from the criteria you want.\n",
    "\n",
    "For example: you could want to just extract a single class, with a probability above 95% and also with predictions box sizes that aren't below 30px in width and height.\n",
    "\n",
    "(Note that the list of boxes and probabilities are `torch.Tensor` objects, if you want to work with numpy you just have to apply `.numpy()` to convert it)\n",
    "\n",
    "I've trained 3 models in order to improve the predictions of the previous one.\n",
    "It worked a bit because of relabeling some too small images, also by training for more epochs.\n",
    "But the best way to improve it would surely be to label more images.\n",
    "\n",
    "Let's take some images and look at the predictions.\n",
    "\n",
    "The third model without any filter gave these predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a40332",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(\"imgs/start_video2.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e254b824",
   "metadata": {},
   "source": [
    "There are a lot, and most of them - especially for traffic signs - aren't good ones.\n",
    "\n",
    "So I've selected only the `traffic_sign` class and tried with several probability thresholds.\n",
    "\n",
    "The best one was to get probability above 95%.\n",
    "I still have false predictions but way less and I don't lose really obvious ones (which happened with a 99% threshold).\n",
    "\n",
    "Here's the predictions with the 95% filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65292db",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(\"imgs/start_video3.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0c7e9",
   "metadata": {},
   "source": [
    "We can see some false predictions like triangle shaped roofs. \n",
    "But fortunately there aren't the majority!\n",
    "Also, we could guess that the classifier we're going to train in the next part wouldn't give it a high probability and we could just filter them.\n",
    "\n",
    "Globaly, all the traffic signs have been detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e375ad5",
   "metadata": {},
   "source": [
    "To create labeled images with the red rectangles with class names and the associate probability, see the `labeled_image_with_object_detection_predictions` function in the `plots.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1264ae4f",
   "metadata": {},
   "source": [
    "To create gif from a set of images: `make_gif` in the `plots.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d38a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
